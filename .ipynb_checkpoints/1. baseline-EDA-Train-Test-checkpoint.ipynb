{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Bin/repos/competitions/O2O-Coupon-Usage-Forecast'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# display for this notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dfoff = pd.read_csv('../../ml-datasets/O2O-Coupon-Usage-Forecast/ccf_offline_stage1_train.csv')\n",
    "dfon = pd.read_csv('../../ml-datasets/O2O-Coupon-Usage-Forecast/ccf_online_stage1_train.csv')\n",
    "dftest = pd.read_csv('../../ml-datasets/O2O-Coupon-Usage-Forecast/ccf_offline_stage1_test_revised.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 探索数据\n",
    "参考单独的 EDA jupyter notebook。\n",
    "## 2. 特征工程\n",
    "### 2.1 折扣率 Discount_rate\n",
    "```python\n",
    "# print(dfoff['Discount_rate'].unique())\n",
    "[nan '150:20' '20:1' '200:20' '30:5' '50:10' '10:5' '100:10' '200:30'\n",
    " '20:5' '30:10' '50:5' '150:10' '100:30' '200:50' '100:50' '300:30'\n",
    " '50:20' '0.9' '10:1' '30:1' '0.95' '100:5' '5:1' '100:20' '0.8' '50:1'\n",
    " '200:10' '300:20' '100:1' '150:30' '300:50' '20:10' '0.85' '0.6' '150:50'\n",
    " '0.75' '0.5' '200:5' '0.7' '30:20' '300:10' '0.2' '50:30' '200:100'\n",
    " '150:5']\n",
    "```\n",
    "\n",
    "根据打印的结果来看，打折率分为 3 种情况：\n",
    "\n",
    "* ‘null’ 表示没有打折\n",
    "* [0,1] 表示折扣率\n",
    "* x:y 表示满 x 减 y\n",
    "\n",
    "那我们的处理方式可以构建 4 个函数，分别提取 4 种特征，分别是：\n",
    "\n",
    "1. 打折类型：Discount_rate_to_type()\n",
    "2. 折扣率：Discount_rate_zero_to_one()\n",
    "3. 满多少：getDiscountMan()\n",
    "4. 减多少：getDiscountJian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 通过不同类型的折扣优惠可以得到类型特征\n",
    "def Discount_rate_to_type(row):\n",
    "    if pd.isnull(row):\n",
    "        return 0\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    elif '.' in row:\n",
    "        return 2\n",
    "\n",
    "# 2. 将 Discount_rate 字符串转化成 [0, 1]之间小数\n",
    "def Discount_rate_zero_to_one(row):\n",
    "    if pd.isnull(row):\n",
    "        return 0\n",
    "    if ':' in row:\n",
    "        sps = row.split(':')\n",
    "        return (float(sps[0]) - float(sps[1])) / float(sps[0])\n",
    "    return float(row)\n",
    "\n",
    "# 3. 统计折扣率满减时需要满多少金额\n",
    "def Discount_rate_man(row):\n",
    "    if pd.isnull(row):\n",
    "        return 0\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 4. 统计折扣率满减时需要满多少金额\n",
    "def Discount_rate_jian(row):\n",
    "    if pd.isnull(row):\n",
    "        return 0\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# 汇总 Discount_rate 特征提取\n",
    "def Discount_rate_feat(df):\n",
    "    df['Discount_rate_type'] = df['Discount_rate'].apply(Discount_rate_to_type)\n",
    "    df['Discount_rate_ratio'] = df['Discount_rate'].apply(Discount_rate_zero_to_one)\n",
    "    df['Discount_rate_man'] = df['Discount_rate'].apply(Discount_rate_man)\n",
    "    df['Discount_rate_jian'] = df['Discount_rate'].apply(Discount_rate_jian)\n",
    "    # 填充缺失值\n",
    "    df['Discount_rate'].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 领券时间\n",
    "还有一点很重要的是领券日期，因为一般而言，周末领取优惠券去消费的可能性更大一些。因此，我们可以构建关于领券日期的一些特征：\n",
    "\n",
    "* weekday : {null, 1, 2, 3, 4, 5, 6, 7}\n",
    "* weekday_type : {1, 0}（周六和周日为1，其他为0）\n",
    "* Weekday_1 : {1, 0, 0, 0, 0, 0, 0}\n",
    "* Weekday_2 : {0, 1, 0, 0, 0, 0, 0}\n",
    "* Weekday_3 : {0, 0, 1, 0, 0, 0, 0}\n",
    "* Weekday_4 : {0, 0, 0, 1, 0, 0, 0}\n",
    "* Weekday_5 : {0, 0, 0, 0, 1, 0, 0}\n",
    "* Weekday_6 : {0, 0, 0, 0, 0, 1, 0}\n",
    "* Weekday_7 : {0, 0, 0, 0, 0, 0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 获取时间是一周的第几天\n",
    "def get_weekday(row):\n",
    "    if pd.isnull(row):\n",
    "        return np.nan\n",
    "    if row == 'nan':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return date(int(row[0:4]), int(row[4:6]), int(row[6:8])).weekday() + 1\n",
    "\n",
    "# 2. 获取是否为周末的特征\n",
    "def get_weekday_type(row):\n",
    "    if row in [6, 7]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "# ## 处理 Date_received，为空的返回为零，其他的按位取\n",
    "# def Date_received_split_month(row):\n",
    "#     if pd.isnull(row):\n",
    "#         return 0\n",
    "#     row_s = str(int(row))\n",
    "#     return float(row_s[4:6])\n",
    "\n",
    "# def Date_received_split_day(row):\n",
    "#     if pd.isnull(row):\n",
    "#         return 0\n",
    "#     row_s = str(int(row))\n",
    "#     return float(row_s[4:6])\n",
    "\n",
    "# 汇总 Date_received 特征\n",
    "def Date_received_feat(df):\n",
    "#     df['Date_received_month'] = df['Date_received'].apply(Date_received_split_month)\n",
    "#     df['Date_received_day'] = df['Date_received'].apply(Date_received_split_day)\n",
    "    \n",
    "    df['weekday'] = df['Date_received'].astype(str).apply(get_weekday)\n",
    "    df['weekday_type'] = df['weekday'].apply(get_weekday_type)\n",
    "    df = pd.concat((df, pd.get_dummies(df['weekday'], prefix='weekday_')), axis=1)\n",
    "    \n",
    "    # 处理缺失值\n",
    "    df['weekday'].fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 距离 Distance\n",
    "距离已经被处理过，那么就主要处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Distance\n",
    "def Distance_feat(df):\n",
    "    # 缺失值\n",
    "    df['Distance'].fillna(df['Distance'].median(), inplace=True)\n",
    "    \n",
    "    # 归一化距离\n",
    "#     df['Distance'] = MinMaxScaler().fit_transform(df['Distance'].values.reshape(-1, 1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 类标\n",
    "标注标签 Label\n",
    "有了特征之后，我们还需要对训练样本进行 label 标注，即确定哪些是正样本（y = 1），哪些是负样本（y = 0）。我们要预测的是用户在领取优惠券之后 15 之内的消费情况。所以，总共有三种情况：\n",
    "\n",
    "1. Date_received == ‘null’：\n",
    "\n",
    "表示没有领到优惠券，无需考虑，y = -1\n",
    "\n",
    "2. (Date_received != ‘null’) & (Date != ‘null’) & (Date – Date_received <= 15)：\n",
    "\n",
    "表示领取优惠券且在15天内使用，即正样本，y = 1\n",
    "\n",
    "3. (Date_received != ‘null’) & ((Date == ‘null’) | (Date – Date_received > 15))：\n",
    "\n",
    "表示领取优惠券未在在15天内使用，即负样本，y = 0\n",
    "\n",
    "好了，知道规则之后，我们就可以定义标签备注函数了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    if row['Date_received'] == 'nan':\n",
    "        return -1\n",
    "    if pd.notnull(row['Date']):\n",
    "        if pd.to_datetime(row['Date'], format='%Y%m%d') - pd.to_datetime(row['Date_received'], format='%Y%m%d') < pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def label_feat(df):\n",
    "    df['label'] = df.apply(get_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程处理类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线下特征处理汇总\n",
    "def off_feats(df_, no_discount_rate=True):\n",
    "    # 创建一个拷贝，修改不影响原数据，这样就不用因为原数据被修改从头 run 一遍，节省时间，不要老对内存扣扣搜搜的，硬件问题不会特别大\n",
    "    df = df_.copy()\n",
    "\n",
    "    df = Discount_rate_feat(df)\n",
    "    df = Date_received_feat(df)\n",
    "    df = Distance_feat(df)\n",
    "#     df = label_feat(df)\n",
    "    \n",
    "    # drop featues\n",
    "    if no_discount_rate:\n",
    "        feats = ['Discount_rate', 'Date_received']\n",
    "        if 'Date' in df.columns:\n",
    "            feats.append('Date')\n",
    "        df.drop(feats, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 待丰富，做特征工程的类\n",
    "class FeatureConverting(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, no_discount_rate=True):\n",
    "        self.no_discount_rate = no_discount_rate\n",
    "    def fit(self, X, y=None):\n",
    "        return self   # Nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        return off_feats(X, self.no_discount_rate)\n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return off_feats(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据：拆分线下数据成训练集和测试集\n",
    "## 找到label\n",
    "dfoff = label_feat(dfoff)\n",
    "train_off, test_off = train_test_split(dfoff, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单模型测试\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 管道机制使得参数集在新数据集（比如测试集）上的重复使用，管道机制实现了对全部步骤的流式化封装和管理。\n",
    "feat_eng = Pipeline([\n",
    "    ('fc', FeatureConverting()), # transformer\n",
    "])\n",
    "\n",
    "feats = ['Discount_rate', 'Distance', 'Date_received', 'Date']\n",
    "feat_eng_tr = feat_eng.fit_transform(train_off[feats])\n",
    "feat_eng_ts = feat_eng.transform(test_off[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001444991713621"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 下采样\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# cc = RandomUnderSampler(random_state=0)\n",
    "\n",
    "# X_train, y_train = cc.fit_sample(feat_eng_tr, train_off['label'])\n",
    "X_train, y_train = feat_eng_tr, train_off['label']\n",
    "\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "y_pred = clf.predict(feat_eng_ts)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(test_off['label'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对结果预测\n",
    "submit = dftest[['User_id', 'Coupon_id', 'Date_received']]\n",
    "\n",
    "feat_dftest = feat_eng.transform(dftest[['Discount_rate', 'Distance', 'Date_received']])\n",
    "\n",
    "submit['Probability'] = clf.predict_proba(feat_dftest)[:,0]\n",
    "submit.to_csv('submission.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:01<00:01,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogisticRegression', 0.7849732755882847, 0.6816543534191699)\n",
      "('GaussianNB', 0.7205499132742075, 0.47964681446362584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:01<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DecisionTreeClassifier', 0.7981439817937237, 0.7234120754351425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 4/4 [00:02<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RandomForestClassifier', 0.7984330558818808, 0.7192494095054661)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 多个模型批量跑\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 管道机制使得参数集在新数据集（比如测试集）上的重复使用，管道机制实现了对全部步骤的流式化封装和管理。\n",
    "feat_eng = Pipeline([\n",
    "    ('fc', FeatureConverting()), # transformer\n",
    "])\n",
    "\n",
    "feats = ['Discount_rate', 'Distance', 'Date_received']\n",
    "feat_eng_tr = feat_eng.fit_transform(train_off[feats])\n",
    "feat_eng_ts = feat_eng.transform(test_off[feats])\n",
    "\n",
    "# 下采样\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "cc = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = cc.fit_sample(feat_eng_tr, train_off['label'])\n",
    "\n",
    "models = tqdm([LogisticRegression(), GaussianNB(), DecisionTreeClassifier(), RandomForestClassifier()])\n",
    "\n",
    "for model in models:\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(feat_eng_ts)\n",
    "    print(type(model).__name__, roc_auc_score(test_off['label'], y_pred), accuracy_score(test_off['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Conda",
   "language": "/Users/Bin/anaconda2/envs/py2/bin/python",
   "name": "python_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
